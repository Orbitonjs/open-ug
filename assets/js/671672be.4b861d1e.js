"use strict";(self.webpackChunkdocumetations=self.webpackChunkdocumetations||[]).push([[8679],{6668:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"a-practical-guide-to-the-event-driven-architecture","metadata":{"permalink":"/open-ug/blog/a-practical-guide-to-the-event-driven-architecture","source":"@site/blog/2025-01-18-eda.md","title":"A Practical Introduction to The Event Driven Architecture","description":"Event Driven Architecture","date":"2025-01-18T00:00:00.000Z","tags":[{"label":"software engineering","permalink":"/open-ug/blog/tags/software-engineering"},{"label":"software architecture","permalink":"/open-ug/blog/tags/software-architecture"},{"label":"tutorial","permalink":"/open-ug/blog/tags/tutorial"},{"label":"redis","permalink":"/open-ug/blog/tags/redis"}],"readingTime":12.145,"hasTruncateMarker":true,"authors":[{"name":"Beingana Jim Junior","title":"Software Engineer","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"}],"frontMatter":{"slug":"a-practical-guide-to-the-event-driven-architecture","title":"A Practical Introduction to The Event Driven Architecture","authors":{"name":"Beingana Jim Junior","title":"Software Engineer","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"},"tags":["software engineering","software architecture","tutorial","redis"]},"unlisted":false,"nextItem":{"title":"Building a Kubernetes Operator | A Practical Guide","permalink":"/open-ug/blog/building-a-kubernetes-operator"}},"content":"![Event Driven Architecture](https://www.cncf.io/wp-content/uploads/2023/10/Screenshot-2023-10-27-at-16.36.16.png)\\n\\nAfter working extensively with microservices, I\u2019ve come to appreciate the power and flexibility of the **Event-Driven Architecture (EDA)**. EDA is a software design pattern that allows systems to detect, process, and react to real-time events in a decoupled manner. It is particularly suited for microservices, enabling seamless communication and interaction between independent components.\\n\\n\x3c!--truncate--\x3e\\n\\nIn this article, we\u2019ll explore the principles of event-driven architecture, discuss its core concepts, and demonstrate how it works using a custom-built command-line tool. This tool, written in Go and powered by Redis, serves as a practical example of EDA in action.\\n\\nTo follow along with the demonstrations, you\u2019ll need the following:\\n\\n- [Download the CLI tool from GitHub](https://github.com/jim-junior/eda/releases) (available for Windows, Linux, and macOS) Make sure to download the latest release.\\n- Have a Redis server running locally. You can install Redis from the official website or use Docker for easier setup (recommended):\\n\\n## How the Event-Driven Architecture Works\\n\\nAt a high level point of view the EDA is quite straight forward. Events representing occurrences or changes in the system drive the flow are generated by various sources (Publishers), published to an event bus or message broker, and consumed by interested components (Consumers) asynchronously. This approach promotes flexibility, scalability, and resilience.\\n\\nAn event is any change in state of the system and can be anything ranging from customer requests, inventory updates, sensor readings, and so on.\\n\\nThe event-driven architecture enables different components of a system to run independently of each other by introducing a middleman known as an **Event broker** that routes events to different intended destination components. This means that applications and devices do not need to know where they are sending information or where the information they are consuming comes from. Rather they focus on carrying out there intended functionality.\\n\\n![Image showing producer](https://jim-junior.github.io/eda1.jpg)\\n\\n> Note: In this article we use Redis because of its simplicity and realatively easy learning curve but Redis wont demonstrate the full functionality of an Event Driven System, however there are other more complex software systems such as RabbitMQ or Apache Kafka that provide a wide range of functionality and Protocals such as AMQP and MQTT(Commonly used in IoT application) that can be used to build more large scale systems, however these have a steep learning curve and wont be ideal for demonstration purposes in this article.\\n\\n## Concepts\\n\\nWith this high level understanding of how the Event-Driven Architecture works, lets look and some of its core concepts. These will give you a platform to weigh the strengths of this architecture to others and possibly give you a basis on deciding when to apply it in your projects. We sha;; use the tool to demonstrate these concepts.\\n\\n### The Event broker\\n\\nAn *Event Broker* is a middleware platform that routes events from source to desired destination. This is accomplished using the publish-subscribe messaging pattern. In this pattern, independent system components connect to the event broker and exchange messages through the Event Broker.\\n\\nMultiple event brokers Exist, some of the most popular ones include Apache Kafka, RabbitMQ, AWS EventBridge, and Redis. In this article, we will use Redis as our event broker. To follow along with the practical example atart you redis instance. Make sure its listening on port `6379` as thats where `eda` cli tool will try to access it from. Unfortunately I had to dard code the port value. You can run the following command to run Redis in a Docker Container.\\n\\n```bash\\ndocker run -d -p 6379:6379 redis\\n```\\n\\n### Event Portals\\n\\nEvent portals in Event-Driven Architecture are tools or platforms designed to facilitate the management, discovery, and governance of events within an event-driven system. They are especially valuable in modern distributed systems where events act as the primary means of communication between components.\\n\\nYou should not confuse them with Event Brokers as the definition might sound similar. Here are the differences\\n\\n| Aspect               | Event Portal                                | Event Broker                             |\\n| -------------------- | ------------------------------------------- | ---------------------------------------- |\\n| **Primary Function** | Discovery, governance, and design of events | Real-time routing and delivery of events |\\n| **Focus**            | Design-time and metadata management         | Runtime event processing                 |\\n| **Scope**            | Entire event-driven system                  | Specific event transportation tasks      |\\n| **Examples**         | AsyncAPI, Solace Event Portal               | Kafka, RabbitMQ, AWS EventBridge         |\\n\\nI found a good article on the Internet explaining Event Portals in detail. [Read it here](https://solace.com/what-is-an-event-portal/)\\n\\n### Event Mesh\\n\\nAn event mesh is created and enabled through a network of interconnected event brokers. It\u2019s a configurable and dynamic infrastructure layer for distributing events among decoupled applications, cloud services, and devices by dynamically routing events to any application, no matter where these applications are deployed in the world, in any cloud, on-premises, or IoT environment. Technically speaking, an event mesh is a network of interconnected event brokers that share consumer topic subscription information and route messages amongst themselves so they can be passed along to subscribers.\\n\\n### **Topics in Event-Driven Architecture**\\n\\nIn an event-driven system, **topics** are labels used to organize and route events. When an event is published, it is associated with a specific topic, and consumers subscribe to topics to receive events relevant to them. This approach allows producers to send events without needing to know which consumers will process them, while consumers only handle events tied to their subscribed topics. For example, an event with the topic `orderCreated` could be published by a producer, and any consumers subscribed to `orderCreated` would receive and process the event.\\n\\nIn this demonstration, we will set up a system with two components: the API server, which acts as the producer, and the consumer, which listens to a topic and logs the events it receives. First, you\u2019ll need to start the API server by running the following command in your terminal:\\n\\n```bash\\neda api-server\\n```\\n\\nThis command initializes the server, which listens for POST requests. These requests include events that the server will publish to Redis, using the specified topic. Next, you\u2019ll start a consumer that subscribes to a particular topic. To subscribe to the topic `orderCreated`, use the following command:\\n\\n```bash\\neda consumer --topic orderCreated\\n```\\n\\nWith both the API server and the consumer running, you can now send an event to the system. Use an HTTP client, such as `curl` or Postman, to send a POST request to the API server. For instance, sending the following request publishes an event to the topic `orderCreated`:\\n\\n```bash\\ncurl -X POST -H \\"Content-Type: application/json\\" \\\\\\n-d \'{\\"order_id\\": 123, \\"customer\\": \\"John Doe\\", \\"total\\": 49.99}\' \\\\\\nhttp://localhost:3000/topics/orderCreated\\n```\\n\\nWhen this request is received, the API server sends the event to Redis, the event broker. Redis routes the event to all consumers subscribed to the topic `orderCreated`. If a consumer is actively listening, it will receive the event and log the message to its console. The consumer\u2019s output will look like this:\\n\\n```bash\\nReceived event on topic: orderCreated\\nEvent data: {\\"order_id\\": 123, \\"customer\\": \\"John Doe\\", \\"total\\": 49.99}\\n```\\n\\nThis demonstration shows how topics allow events to be routed to the appropriate consumers without requiring direct communication between the producer and the consumers. By associating events with topics, the system achieves flexibility and scalability while keeping its components decoupled.\\n\\n### Deferred Execution\\n\\nDeferred execution is a key concept in event-driven architecture that differs significantly from traditional REST-based APIs. In a REST-based system, when you send a request, you typically wait for an immediate response. However, in event-driven systems, you don\u2019t wait for a response when you publish an event. Instead, the event is handed off to an event broker, which holds or persists the event until consumers are ready to process it. This allows for more flexible and decoupled communication, as consumers can process events at their own pace, potentially much later.\\n\\nIn this approach, acting on one event might also cause new events to be generated and persisted in the event broker. These subsequent events can trigger further actions in other parts of the system, creating a chain of reactions, all while maintaining the flexibility of deferred processing.\\n\\nTo understand this concept better, let\u2019s walk through a practical demonstration of deferred execution.\\n\\n#### Practical Demonstration\\n\\nIn this demonstration, you will observe how events can be held in a queue and processed after a delay, demonstrating deferred execution. Here are the steps:\\n\\n1. **Start the API Server**  \\n\\nFirst, start the API server, which allows you to publish events to the system:\\n\\n```bash\\neda api-server\\n```\\n\\nThis server listens for POST requests and routes event messages to the system.\\n\\n1. **Send an Event**\\n\\nSend a POST request to the `/deferred-exec` endpoint of the API server. The request body contains the event message you want to publish. For example:\\n\\n```bash\\ncurl -X POST -H \\"Content-Type: application/json\\" \\\\\\n-d \'{\\"task_id\\": 456, \\"description\\": \\"Process data files\\"}\' \\\\\\nhttp://localhost:3000/deferred-exec\\n```\\n\\nWhen this request is sent, the API server pushes the event to Redis, the event broker, where it will be stored in a queue for processing.\\n\\n1. **Start the Master Node**  \\n\\nNext, start the master node, which plays a key role in deferred execution by sending events from Redis to the event queue. To start the master node, run the following command:\\n\\n```bash\\neda consumer -d --master\\n```\\n\\n1. **Start a Consumer**  \\n\\nFinally, run the consumer to process events from the event queue. The consumer checks the queue every 10 seconds, retrieves the events, and logs them to demonstrate deferred execution. To start the consumer, use the command:\\n\\n```bash\\neda consumer -d\\n```\\n\\nOnce the consumer is running, you will see a 10-second delay before the consumer processes events. For example, the consumer\u2019s log might display:\\n\\n```bash\\nProcessing event: {\\"task_id\\": 456, \\"description\\": \\"Process data files\\"}\\n```\\n\\nThis delay illustrates how events can be stored in a queue and processed later, at the consumer\u2019s convenience. Such deferred execution is particularly useful in scenarios where immediate processing isn\u2019t required, allowing for greater flexibility and resource efficiency.\\n\\n### Eventual Consistency\\n\\nBuilding on the concept of deferred execution, where events are processed at a later time rather than immediately, we encounter the idea of eventual consistency. In an event-driven system, since events are not processed instantly, there\u2019s no guarantee that all components, such as databases or systems, are synchronized at any given moment. For example, if you have multiple systems\u2014like a database, a master data management (MDM) system, and an ERP\u2014they may not have the same state at the same time.\\n\\nIn our deferred execution demonstration, when an event (like a task or an order) is published to Redis, it may take time for the consumer to process it. Until the consumer acts on the event and updates the relevant systems, those systems might not reflect the latest state. However, while consistency isn\u2019t immediate, we can rely on the system to eventually synchronize. This means that all stateful components will reach a consistent state over time, provided the system is functioning as intended and events are processed correctly.\\n\\nFor example, after publishing a task event with the API server, the consumer may process it after a delay, updating the system state accordingly. While the task\'s status may appear outdated immediately after publication, you can trust that the system will catch up and reflect the changes eventually.\\n\\nThis principle is particularly useful in distributed systems, where maintaining immediate consistency across all components can be impractical or inefficient. By embracing eventual consistency, we trade immediate synchronization for better scalability and resilience, trusting the system to converge to a consistent state in due time.\\n\\n### Choreography  \\n\\nIn the world of event-driven architecture, **choreography** is a pattern where multiple components interact and coordinate their actions by responding to shared events. Unlike orchestration, where a central controller dictates the flow of operations, choreography allows each component to act independently based on the events it receives. This decentralized approach aligns well with the principles of EDA, promoting loose coupling and scalability.  \\n\\n#### Benefits of Choreography  \\n\\nChoreography ensures that components operate independently, reducing the risk of bottlenecks or single points of failure. In our system, the master node facilitates event flow but does not tightly couple itself to the consumers. This allows for easy scaling\u2014new consumers can join without the master node needing to know about them, as long as they subscribe to the appropriate topics or queues.  \\n\\nBy adopting choreography, you can build systems that are more resilient and flexible. Each component focuses on its responsibilities, reacting to events as needed, rather than relying on a central controller to orchestrate every action.  \\n\\n### CQRS:Command Query Responsibility Segregation\\n\\nCQRS is a method for scaling microservices by separating responsibilities. One service handles commands, such as updates or inserts, while another handles queries, such as fetching data. This separation is useful because query services often need to handle far more requests than commands, making it easier to scale the query service independently.\\n\\nIn an event-driven architecture, implementing CQRS is straightforward. Events in the system can be categorized by topics that include a specific action or verb, like \\"query\\" or \\"update.\\" To scale the query service, you can simply deploy more instances of it and have them listen to the topics related to queries. This way, the system remains efficient, scalable, and easy to manage.\\n\\n## Conclusion\\n\\nEvent-Driven Architecture (EDA) is a powerful paradigm that enables systems to be more flexible, scalable, and resilient by decoupling components and allowing them to communicate through events. Throughout this article, we\u2019ve explored the principles of EDA, discussed its core concepts like deferred execution, eventual consistency, choreography, and CQRS, and demonstrated how these concepts can be applied in practice using Redis and a custom-built CLI tool.\\n\\nBy embracing EDA, you can design systems that not only handle complex workflows efficiently but also adapt to changing demands with ease. Whether you\'re scaling query services, coordinating actions through events, or ensuring eventual consistency in distributed systems, EDA provides the tools and patterns to build robust architectures.\\n\\nThank you for taking the time to read this article! I hope it has been informative and inspires you to experiment with EDA in your own projects. About me, I am [Beingana Jim Junior](https://jim-junior.github.io/), a software engineering student at Makerere University, I love sharing insights from my learning and experiences. I\u2019m passionate about software design and always eager to explore new technologies and solutions. Check out my [Github](https://github.com/jim-junior) and [Portifolio website](https://jim-junior.github.io/)\\n\\nFeel free to share your thoughts, questions, or feedback. I\u2019d love to hear from you. Let\u2019s continue building amazing systems together!\\n\\n\\n## References\\n\\nEvent-Driven Architecture. Amazon Web Services. [https://aws.amazon.com/event-driven-architecture/](https://aws.amazon.com/event-driven-architecture/)\\n\\nEvent-Driven Architecture (EDA) - A Complete Introduction. Confluent. [https://www.confluent.io/learn/event-driven-architecture/](https://www.confluent.io/learn/event-driven-architecture/)\\n\\nThe Complete Guide to Event-Driven Architecture. Medium. [https://medium.com/@seetharamugn/the-complete-guide-to-event-driven-architecture-b25226594227](https://medium.com/@seetharamugn/the-complete-guide-to-event-driven-architecture-b25226594227)"},{"id":"building-a-kubernetes-operator","metadata":{"permalink":"/open-ug/blog/building-a-kubernetes-operator","source":"@site/blog/2024-12-28-operator.md","title":"Building a Kubernetes Operator | A Practical Guide","description":"One of those great revolutionary technologies that have transformed how developers think of and Interact with cloud infrastructure is Kubernetes. Initially Developed at Google, Kubernetes, also known as K8s, is an open source system for automating deployment, scaling, and management of containerized applications. It is Designed on the same principles that allow Google to run billions of containers a week, Kubernetes can scale without increasing your operations team.","date":"2024-12-28T00:00:00.000Z","tags":[{"label":"kubernetes","permalink":"/open-ug/blog/tags/kubernetes"},{"label":"devops","permalink":"/open-ug/blog/tags/devops"},{"label":"tutorial","permalink":"/open-ug/blog/tags/tutorial"},{"label":"go","permalink":"/open-ug/blog/tags/go"}],"readingTime":30.75,"hasTruncateMarker":true,"authors":[{"name":"Beingana Jim Junior","title":"Software Engineer","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"}],"frontMatter":{"slug":"building-a-kubernetes-operator","title":"Building a Kubernetes Operator | A Practical Guide","authors":{"name":"Beingana Jim Junior","title":"Software Engineer","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"},"tags":["kubernetes","devops","tutorial","go"]},"unlisted":false,"prevItem":{"title":"A Practical Introduction to The Event Driven Architecture","permalink":"/open-ug/blog/a-practical-guide-to-the-event-driven-architecture"},"nextItem":{"title":"How to create a responsive custom video player in React","permalink":"/open-ug/blog/how-to-create-a-responsive-custom-video-player-in-react"}},"content":"![](https://www.epsglobal.com/Media-Library/EPSGlobal/Blog/kubernets2.jpg)\\n\\nOne of those great revolutionary technologies that have transformed how developers think of and Interact with cloud infrastructure is Kubernetes. Initially Developed at Google, Kubernetes, also known as K8s, is an open source system for automating deployment, scaling, and management of containerized applications. It is Designed on the same principles that allow Google to run billions of containers a week, Kubernetes can scale without increasing your operations team.\\n\\n\x3c!--truncate--\x3e\\n\\nDespite its remarkable capabilities, Kubernetes is fundamentally a container orchestration technology. While it greatly simplifies deployment and scaling, it doesn\'t address all challenges that software engineers encounter in software development and DevOps. To Solve this Kubernetes provides ways it can be Extended and customized to meet your team\'s needs. It Provides Client Libraries in many languages. But even better are Kubernetes Operators.\\n\\nA formal definition of a kubernetes operator can be:\\n\\n> A Kubernetes Operator is a method of automating the management of complex applications on Kubernetes. It extends Kubernetes\' capabilities by using custom resources and controllers to manage the lifecycle of an application, automating tasks such as deployment, scaling, and updates. Operators encode the operational knowledge of an application into Kubernetes, making it easier to manage stateful or complex workloads with less manual intervention.\\n\\nIn this article. We shall go through a guide to get started building your own Custom kubernetes Operator. We shall cover different topics like Custom Resource Definitions, Controllers and look at the Kubernetes Controller Runtime.\\n\\n## Prerequisites\\n\\nThere are a few thing we need to know and have before continuing with this tutorial\\n\\n- A good understanding of Kubernetes and how to use it.\\n- Programming Knowledge in the Go Programming Language.\\n- Access to a Kubernetes Cluster (You can try it locally using Minikube or Kind)\\n\\nTo set up your environment you will first need to have Go installed. The Kubernetes Golang Client usually requires a specific Go version so depending on your time of reading this article it might have changed but for now i will use `go1.21.6`. To know what version you are using, run\\n\\n```bash\\ngo version\\n# Example output: go version go1.21.6 linux/amd64\\n```\\n\\nNext you will need to have access to a Kubernetes cluster but for development purposes I would advise you use a local cluster from tools like [Minikube](https://minikube.sigs.k8s.io/docs/start) or [Kind](https://kind.sigs.k8s.io/). You can visit their websites for the installation steps.\\n\\nBefore we dive right into code. There are certain key concepts you will need to know so let\'s look at those first.\\n\\n## Concepts\\n\\n### Custom Resource Definitions (CRDS)\\n\\nTo understand CRDs you need to first know what a resource is. Pods, Deployments, Services etc are all resources. Formally\\n\\n> A resource is an endpoint in the [Kubernetes API](https://kubernetes.io/docs/concepts/overview/kubernetes-api/) that stores a collection of [API objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/#kubernetes-objects) of a certain kind; for example, the built-in pods resource contains a collection of Pod objects.\\n\\nResources are in built within the Kubernetes API. But in our case, we said one of the main resons we build operators is to handle custom problems that Kubernetes does not solve out of the box. In some cases we might need to define our own resource objects. Forexample. Imagine we are building an operator that manages postgreSql databases, we would like to provide an API to define configurations of each database we initiate, we can do this by defining a Custom resource definition `PGDatabase` as an Object that stores the configuration of the database.\\n\\n__Example of a Custom Resource Definition for demostration__\\n\\n```yml\\napiVersion: example.com/v1 # Every resource must have an API Version \\nkind: PGDatabase # CRD Name\\nmetadata:\\n  name: mydb\\nspec:\\n  config:\\n    port: 5432\\n    user: root\\n    dbname: mydb\\n\\n  volumes:\\n  - pgvolume: /pgdata/\\n\\n  envFrom: wordpress-secrets\\n```\\n\\nNote: CRDs are just definitions of the actually objects or they just represent an actual object in the kubernetes cluster but are not the actual object. For example when you write a `yaml` file defining how a pod should be scheduled, that `yaml` just defines but its not the actual pod.\\n\\nTherefore we can define a CRD as an extension of the Kubernetes API that is not necessarily available in a default Kubernetes installation. It represents a customization of a particular Kubernetes installation. Actually, many core Kubernetes functions are now built using custom resources, making Kubernetes more modular.\\n\\n### Controllers\\n\\nNext Lets look at Kubernetes Controllers. As we have seen above, CRDs represent objects or state of objects in the Kubernetes Cluster, but we need something to reconcile or transform that state into actual resources on the cluster, this is where Controllers come in.\\n\\n> A Kubernetes controller is a software component within Kubernetes that continuously monitors the state of cluster resources and takes action to reconcile the actual state of the cluster with the desired state specified in resource configurations (YAML files).\\n\\n\\n![Controller life cylce](https://iximiuz.com/writing-kubernetes-controllers-operators/kdpv.png)\\n\\nControllers are responsible for managing the lifecycle of Kubernetes objects, such as Pods, Deployments, and Services. Each controller typically handles one or more resource types and performs tasks like creating, updating, or deleting resources based on a declared specification.\\nHere\'s a breakdown of how a Kubernetes controller operates:\\n\\n1. __Observe__: The controller watches the API server for changes to resources it\'s responsible for. It monitors these resources by querying the Kubernetes API periodically or via an event stream.\\n2. __Analyze__: It compares the actual state (current conditions of the resources) to the desired state (specified in configurations).\\n3. __Act__: If there\u2019s a discrepancy between the actual and desired state, the controller performs operations to align the actual state with the desired state. For example, a Deployment controller might create or terminate Pods to match the specified replica count.\\n4. __Loop__: The controller operates in a loop, continuously monitoring and responding to changes to ensure the system\u2019s resources are always in the desired state.\\n\\n### Controller Runtime\\n\\nKubernetes provides a set of tools to build native Controllers and these are Known as the Controller Runtime.\\n\\nLets take a deep look into the Controller runtime because its what we shall be using to build out Operators\\n\\n## A Deep look into the Controller Runtime\\n\\nController Runtime is a set of libraries and tools in the Kubernetes ecosystem, designed to simplify the process of building and managing Kubernetes controllers and operators. It\u2019s part of the Kubernetes Operator SDK and is widely used to develop custom controllers that can manage Kubernetes resources, including custom resources (CRDs).\\n\\nController Runtime provides a structured framework for controller logic, handling many of the lower-level details of working with the Kubernetes API, so developers can focus more on defining the behavior of the controller and less on boilerplate code. It is written in Go and builds on the Kubernetes `client-go` libraries.\\n\\nTo use it, you can add it to you golang project by importing it like this:\\n\\n```go\\npackage controller\\n\\n// Controller runtime packages\\nimport (\\n\\t\\"sigs.k8s.io/controller-runtime\\"\\n\\t\\"sigs.k8s.io/controller-runtime/pkg/client\\"\\n)\\n\\n```\\n\\n> __Note__: The Controller runtime is not the only way one can build a Kubernetes Operator, there are multiple ways to do so such as using the [Operator Framework SDK](https://sdk.operatorframework.io/) or [Kubebuilder](https://book.kubebuilder.io/), which are both frameworks built on top of the Controller runtime and utilize it under the hood to assist you when building complex Operators. You could even build an application that utilizes the Kubernetes Rest API through client libraries in various languages such as Python, Java, JavaScript etc depending on your tech stack. Find the Full list of Client Libraries on the [Kubernetes Documentation](https://kubernetes.io/docs/reference/using-api/client-libraries/).\\n> In this article, we will use the Controller runtime because it offers flexibility and provides a hands-on understanding of how Controllers work internally. This approach is ideal for gaining deeper insight into the inner workings of Kubernetes Operators while maintaining the ability to extend or customize as needed.\\n\\n### Key Components of Controller Runtime\\n\\nThe Controller Runtime has several key components that streamline the process of building and running Kubernetes controllers. Together, these components create a robust framework for building Kubernetes controllers.\\n\\nThe Manager initiates and manages other components; the Controller defines reconciliation logic; the Client simplifies API interactions; the Cache optimizes resource access; Event Sources and Watches enable event-driven behavior; and the Reconcile Loop ensures continuous alignment with the desired state. These components make it easier to build controllers and operators that efficiently manage Kubernetes resources, allowing for custom automation and orchestration at scale.\\n\\n#### 1.  Manager\\n\\nThe Manager is the main entry point of a controller or operator, responsible for initializing and managing the lifecycle of other components, such as controllers, caches, and clients. Developers usually start by creating a Manager in the main function, which acts as the foundational setup for the entire operator or controller.\\n\\nIt provides shared dependencies (e.g., the Kubernetes client and cache) that can be reused across controllers, allowing multiple controllers to be bundled within a single process.\\n\\nThe Manager also coordinates starting and stopping all controllers it manages, ensuring that they shut down gracefully if the Manager itself is stopped.\\n\\n#### 2. Controller\\n\\nThe Controller is the core component that defines the reconciliation logic responsible for adjusting the state of Kubernetes resources. It is a control loop that monitors a cluster\'s state and makes changes to move it closer to the desired state\\n\\n![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zacjsy7nznxEgFhxJFfC0w.png)\\n\\nEach controller watches specific resources, whether built-in (e.g., Pods, Deployments) or custom resources (CRDs). It includes a `Reconcile` function that\u2019s triggered whenever a resource changes, allowing the controller to bring the current state in line with the desired state.\\n\\nDevelopers specify which resources the controller should watch, and Controller Runtime will automatically track and respond to events (like create, update, delete) for those resources. In a controller for managing custom `Foo` resources, the `Reconcile` function might create or delete associated resources based on Foo specifications.\\n\\n#### 2. Client\\n\\nWhen building a Kubernetes operator, you need some interface to interact with the Kubernetes Cluster and carry out your operations. Just like `kubectl` the command line client we use, the Controller runtime provided a `client` in its SDK tools. This client is also used to interact with the Kubernetes API pragrammatically in your code.\\n\\nThe Client is *an abstraction that simplifies interactions with the Kubernetes API*, enabling CRUD operations on resources.\\n\\nThis component allows for easy creation, reading, updating, and deletion of Kubernetes resources.\\nThe Client is integrated with the cache to provide efficient access to resources without overloading the API server.\\n\\nController Runtime\u2019s Client extends the basic Kubernetes `client-go` library, making API calls more straightforward by handling details like retries and caching behind the scenes.\\n\\nUsing the Client, developers can create a Pod directly from the controller logic with a single line of code, `client.Create(ctx, pod)`, without having to worry about raw API requests.\\n\\n#### 3. Event Sources and Watches\\n\\nEvent Sources and Watches determine the resources that a controller will monitor for changes, providing a way to respond to specific events in the cluster.\\n\\nEvent Sources define what triggers the controller\u2019s reconciliation loop, which can be based on changes in specific Kubernetes resources.\\nWatches monitor these resources, allowing the controller to act on create, update, or delete events as needed.\\n\\nDevelopers can define multiple Watches for a single controller, which is useful if the controller\u2019s behavior depends on multiple resources.\\n\\nA controller managing a custom `App` resource might watch Pods, Services, and ConfigMaps, reacting to changes in any of these resources by adjusting the `App` accordingly.\\n\\n#### 4. Reconcile Loop\\n\\nThe Reconcile loop is the heart of the controller, implementing the main logic that determines the steps to bring resources into the desired state.\\nEach controller\u2019s Reconcile function checks the actual state of a resource and then applies necessary changes to make it conform to the desired state.\\nThis loop continues indefinitely, with each reconciliation acting as a self-healing mechanism to correct any divergence from the specification.\\nThe Reconcile loop is usually idempotent, meaning it can be repeated without causing unintended side effects, ensuring consistency even with frequent updates.\\nIn a Reconcile function, the controller might find that a Deployment lacks the specified number of replicas, so it updates the Deployment configuration to match the desired replica count.\\n\\n## A Practical Example\\n\\nNow that you have grasped a few required concepts, lets take a practical approach by building a simple kubernetes oparator and deploying it on our Kubernetes Cluster. This will help you to apply the concepts above and understand the process more.\\n\\nIn this section, we will build a simple Kubernetes operator that helps deploy applications using a custom resource definition (CRD). This operator will automate the creation of Deployments and Services based on the application configuration provided in the custom resource. By the end, you\'ll have a working operator deployed on a Kubernetes cluster and understand its key components.\\n\\n> - All code will be made available on Github at [https://github.com/jim-junior/crane-operator](https://github.com/jim-junior/crane-operator)\\n> - I will ensure code is commented in detail to ensure you can easily read and understand it\\n\\n### Operator Requirements\\n\\nOur goal is to minimize the complexity of defining Kubernetes resources for deploying an application. Instead of writing multiple YAML files for Deployments, Services, etc., we will define a single CRD Application that encapsulates all required configurations. The operator will then create the necessary Kubernetes resources automatically.\\n\\n__Requirements for the Example:__\\n\\n- The operator shall define a CRD *Application* that includes all the configuration of the application.\\n- From the CRD, it should create the associated Kubernetes resources such and Deployments, Services\\n- We shall Implement a controller to reconcile the state of *Application* resources.\\n- Use the controller to create and manage *Deployments* and *Services*.\\n\\nNow that we have a high level understanding of what our Operator is supposed to do and accomplish, lets setup our project and get started building the operator.\\n\\n### Setting up the Project\\n\\nAs mentioned earlier, we will use the Go programming language for this tutorial. Why Go? Primarily because the Controller runtime, as well as Kubernetes itself, is built using Go. Additionally, Go is specifically designed with features that make it ideal for building cloud-native applications. Its architecture ensures that your Operator will be well-suited to scale efficiently in cloud environments. We are using `go1.21.6`\\n\\nSo lets begin by initialising out Go project:\\n\\n```bash\\nmkdir app-operator && cd app-operator\\n\\ngo mod init https://github.com/jim-junior/crane-operator\\n```\\n\\nWe shall then install the go dependencies that we shall use in our project. You can install then by running this in the command line.\\n\\n```bash\\ngo get sigs.k8s.io/controller-runtime\\ngo get k8s.io/apimachinery\\ngo get k8s.io/client-go\\n```\\n\\nNext lets setup our project file/directory structure. Depending on your development paradigm you can choose one that favours you but for now we shall use this simple that i have found to work in most Operator projects.\\n\\n```txt\\napp-operator/\\n\u251c\u2500\u2500 api/                  # Contains CRD definitions\\n\u251c\u2500\u2500 cmd/controller/         \\n    \u251c\u2500\u2500reconciler.go      # Contains the reconciliation logic\\n\u251c\u2500\u2500 main.go               # Entry point for the operator\\n\u251c\u2500\u2500 config/               # Configuration files for testing and deployment\\n```\\n\\n### Defining the Custom Resource Definition (CRD)\\n\\nAs metioned above, the CRD defines the specification of how our Object will look like. From familiarity with deploying multiple applications or web services, there are a few things an application needs:\\n\\n- A port to expose your application\\n- A Volume, incase you want to Persist Data\\n- A Container Image for application distribution and deployment\\n- Enviroment Variables\\n\\nSince this is just an example we shall keep the requirements as minimal as possible, its not like we are building some operator to be used in an actual Organisation. Plus I dont want the code to become huge.\\n\\nWhen defining a Custom Resource Definition (CRD), it must be specified in two formats. The first is as a `yaml` or `json` OpenAPI specification (`yaml` is preffered is its more human readable), which can be applied using `kubectl apply` to install the CRD on a Kubernetes cluster. The second is as a Go language specification, used in your code to define and interact with the CRD programmatically.\\n\\nWhile tools like Operator SDK and Kubebuilder can automatically generate one or both of these formats for you, it\'s important for a developer building a Kubernetes Operator to understand the configurations being generated. This knowledge is invaluable for debugging or handling custom scenarios that may arise.\\n\\nLets begin first with an example showing how we would like our CRD to look like. This will help use comeup with a Specification. Incase you dont understand some aspects of it, dont worry, we shall look into everything.\\n\\n```yml\\napiVersion: operator.com/v1\\nkind: Application\\nmetadata:\\n  name: mysql\\nspec:\\n  image: mysql:9.0\\n  ports:\\n  - internal: 3306\\n    external: 3306\\n\\n  volumes:\\n  - volume-name: /data/\\n\\n  envFrom: mysql-secrets\\n```\\n\\nBefore we define the Open API Specification, lets look at what each component means in out CRD above.\\n\\n```yml\\napiVersion: operator.com/v1\\n```\\nThis defines the Version of your resource. Every resource on kubernetes __MUST__ have an api version. Even inbuilt kubernetes resources have. I would recommend versioning your resources while following the Kubernetes API versioning convetions.\\n\\nKubernetes API versioning follows conventions that reflect the maturity and stability of an API. Here\u2019s a list of the common versioning conventions and what each represents:\\n\\n- __Alpha__ (e.g., *v1alpha1*): Experimental and not stable.\\n- __Beta__ (e.g., *v1beta1*): More stable than alpha but still under active development.\\n- __Stable__ (e.g., *v1*): Fully stable and backward-compatible.\\n\\nKubernetes APIs use a convention of `<group>/<version>` (e.g., `apps/v1`), where:\\n\\n- __Group__: The API group (e.g., *apps*, *batch*, *core*).\\n- __Version__: The maturity level of the API (*v1alpha1*, *v1beta1*, *v1*).\\n\\nCustom Resource Definitions (CRDs) follow the same versioning principles as core Kubernetes APIs.\\n\\nLets move on to.\\n\\n```yml\\nkind: Application\\n```\\n\\nIn Kubernetes, the kind field in a resource manifest specifies the type of resource being defined or manipulated. It is a crucial identifier that tells Kubernetes which resource object the YAML or JSON file represents, enabling the API server to process it accordingly. [Learn more here](https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds)\\n\\n> Note: The value is case-sensitive and typically written in PascalCase (e.g., `ConfigMap`, `Deployment`).\\n\\nNext is\\n\\n```yml\\nspec:\\n  .....\\n```\\n\\nThis is where you define the properties of your CRD.\\n\\n#### Open API Specification\\n\\nWe can now define the Open API Specification for the CRD. You basically have to transform the above `yaml` into an Open API Specification. You can learn more about [Open API Specification on its Documentation](https://swagger.io/specification/). But its pretty straight forward. For the above CRD this is what it would look like.\\n\\n```yml\\napiVersion: apiextensions.k8s.io/v1\\nkind: CustomResourceDefinition\\nmetadata:\\n  name: applications.operator.com\\nspec:\\n  group: operator.com\\n  names:\\n    kind: Application\\n    plural: applications\\n    singular: application\\n  scope: Namespaced\\n  versions:\\n  - name: v1\\n    served: true\\n    storage: true\\n    schema:\\n      openAPIV3Schema:\\n        type: object\\n        properties:\\n          apiVersion:\\n            type: string\\n          kind:\\n            description: \'You can provide a description\'\\n            type: string\\n          metadata:\\n            type: object\\n          spec:\\n            type: object\\n            properties:\\n              # image name\\n              image:\\n                type: string\\n              # Volumes\\n              volumes:\\n                type: array\\n                items:\\n                  type: object\\n                  properties:\\n                    volume-name:\\n                      type: string\\n                    path:\\n                      type: string\\n              # Port Configuration\\n              ports:\\n                type: array\\n                items:\\n                  type: object\\n                  properties:\\n                    name:\\n                      type: string\\n                    internal:\\n                      type: integer\\n                      format: int64\\n                    external:\\n                      type: integer\\n                      format: int64\\n              # Environment variables\\n              envFrom:\\n                type: string\\n```\\n> Note that even the Specification is also a resource in Kubernetes of kind `CustomResourceDefinition`\\n\\nYou can now store that code in the file located in `app-operator/config/crd.yml`.\\n\\n#### Go Lang CRD Definition\\n\\nWe can now define our CRD in Go code. When defininga CRD in Go. We need to do the following\\n\\n- Define the CRD Specification\\n- Define a *deepCopy* function that defines how kubernetes copies the CRD object into another object\\n- Setup code for Registering the CRD\\n\\nWe use Go Structs to define the CRD. Probably due to how it is easy to define JSON-like data structures usung structs. Create a file in `app-operator/api/v1/application.go` and save the following code in it.\\n\\n```go\\npackage v1\\n\\nimport metav1 \\"k8s.io/apimachinery/pkg/apis/meta/v1\\"\\n\\n// This defines an instance of multiple Application resources\\ntype ApplicationList struct {\\n  metav1.TypeMeta `json:\\",inline\\"`\\n  metav1.ListMeta `json:\\"metadata,omitempty\\"`\\n\\n  Items []Application `json:\\"items\\"`\\n}\\n\\n// This defines our CRD\\ntype Application struct {\\n  metav1.TypeMeta   `json:\\",inline\\"`\\n  metav1.ObjectMeta `json:\\"metadata,omitempty\\"`\\n\\n  Spec ApplicationSpec `json:\\"spec\\"`\\n}\\n\\ntype ApplicationSpec struct {\\n  Image     string               `json:\\"image\\"`\\n  Volumes   []ApplicationVolume  `json:\\"volumes\\"`\\n  Ports     []ApplicationPortMap `json:\\"ports\\"`\\n  EnvFrom   string               `json:\\"envFrom\\"`\\n}\\n\\ntype ApplicationVolume struct {\\n  VolumeName string `json:\\"volume-name\\"`\\n  Path       string `json:\\"path\\"`\\n}\\n\\ntype ApplicationPortMap struct {\\n  Name     string `json:\\"name\\"`\\n  Internal int    `json:\\"internal\\"`\\n  External int    `json:\\"external\\"`\\n}\\n```\\n\\nNext lets write the code that defines the Deep Copy functions. In you project create a file in `app-operator/api/v1/deepcopy.go`. And add the following code\\n\\n```go\\npackage v1\\n\\nimport \\"k8s.io/apimachinery/pkg/runtime\\"\\n\\n// DeepCopyInto copies all properties of this object into another object of the\\n// same type that is provided as a pointer.\\nfunc (in *Application) DeepCopyInto(out *Application) {\\n  out.TypeMeta = in.TypeMeta\\n  out.ObjectMeta = in.ObjectMeta\\n  out.Spec = ApplicationSpec{\\n    Volumes: in.Spec.Volumes,\\n    Ports:   in.Spec.Ports,\\n    EnvFrom: in.Spec.EnvFrom,\\n    Image:   in.Spec.Image,\\n  }\\n}\\n\\n// DeepCopyObject returns a generically typed copy of an object\\nfunc (in *Application) DeepCopyObject() runtime.Object {\\n  out := Application{}\\n  in.DeepCopyInto(&out)\\n\\n  return &out\\n}\\n\\n// DeepCopyObject returns a generically typed copy of an object\\nfunc (in *ApplicationList) DeepCopyObject() runtime.Object {\\n  out := ApplicationList{}\\n  out.TypeMeta = in.TypeMeta\\n  out.ListMeta = in.ListMeta\\n\\n  if in.Items != nil {\\n    out.Items = make([]Application, len(in.Items))\\n    for i := range in.Items {\\n      in.Items[i].DeepCopyInto(&out.Items[i])\\n    }\\n  }\\n\\n  return &out\\n}\\n```\\n\\nLastly lets write the code that defines how our CRD is registed. In you project create a file in `app-operator/api/v1/register.go`. And add the following code\\n\\n```go\\npackage v1\\n\\nimport (\\n  metav1 \\"k8s.io/apimachinery/pkg/apis/meta/v1\\"\\n  \\"k8s.io/apimachinery/pkg/runtime\\"\\n  \\"k8s.io/apimachinery/pkg/runtime/schema\\"\\n)\\n\\n// Define the API group name for the custom resource\\nconst GroupName = \\"operator.com\\"\\n// Define the API group version for the custom resource\\nconst GroupVersion = \\"v1\\"\\n\\n// Create a GroupVersion object that combines the group and version\\nvar SchemeGroupVersion = schema.GroupVersion{Group: GroupName, Version: GroupVersion}\\n\\n\\n// SchemeBuilder is a runtime.SchemeBuilder used to add types to the scheme\\nvar (\\n  SchemeBuilder = runtime.NewSchemeBuilder(addKnownTypes)  // Initializes the SchemeBuilder with the addKnownTypes function\\n  AddToScheme   = SchemeBuilder.AddToScheme  // Provides a shorthand for adding types to the scheme\\n)\\n\\n\\n// addKnownTypes registers the custom resource types with the runtime.Scheme\\nfunc addKnownTypes(scheme *runtime.Scheme) error {\\n  // Register the custom resources Application and ApplicationList with the scheme\\n  scheme.AddKnownTypes(SchemeGroupVersion,\\n    &Application{},\\n    &ApplicationList{},\\n  )\\n\\n  // Add the group version to the scheme for metav1 objects\\n  metav1.AddToGroupVersion(scheme, SchemeGroupVersion)\\n  return nil // Return nil to indicate success\\n}\\n```\\n\\nWe can now move on to the next section of Implementing the Controller that will transform our CRD state into the desired objects on the kubernetes cluster.\\n\\n### Implementing the Controller\\n\\nNow that we have our CRD definitions implemented, lets move on to creating our controller that will watch the CRD state and transform it into desired Kubernetes onjects which will be Deployements and Services. To accomplish this we shall visits a few of the concepts we metioned earlier about the Controllers. We shall create the following:\\n\\n- A Manager that will be the entry point of our Controller\\n- The Reconcile function that reconciles the CRD state into desired state on the Cluster\\n- Utility functions that carry out the tasks our operator intends to accomplish\\n\\nIn the `app-operator/cmd/controller/reconciler.go`, paste this code. Dont wory we shall look at each block in detail and what it accomplishes.\\n\\n```go\\npackage controller\\n\\nimport (\\n  \\"context\\"\\n  \\"errors\\"\\n  \\"fmt\\"\\n  \\"os\\"\\n  \\"path/filepath\\"\\n\\n  cranev1 \\"github.com/jim-junior/crane-operator/api/v1\\"\\n  craneKubeUtils \\"github.com/jim-junior/crane-operator/kube\\"\\n\\n  k8serrors \\"k8s.io/apimachinery/pkg/api/errors\\"\\n  \\"k8s.io/apimachinery/pkg/runtime\\"\\n  utilruntime \\"k8s.io/apimachinery/pkg/util/runtime\\"\\n  \\"k8s.io/client-go/kubernetes\\"\\n  \\"k8s.io/client-go/rest\\"\\n  \\"k8s.io/client-go/tools/clientcmd\\"\\n  \\"k8s.io/client-go/util/homedir\\"\\n  ctrl \\"sigs.k8s.io/controller-runtime\\"\\n  \\"sigs.k8s.io/controller-runtime/pkg/client\\"\\n  \\"sigs.k8s.io/controller-runtime/pkg/log\\"\\n  \\"sigs.k8s.io/controller-runtime/pkg/log/zap\\"\\n)\\n\\n// Global variables for the Kubernetes scheme and logger\\nvar (\\n  scheme   = runtime.NewScheme()\\n  setupLog = ctrl.Log.WithName(\\"setup\\")\\n)\\n\\n// Initialize the scheme by registering the cranev1 API group\\nfunc init() {\\n  utilruntime.Must(cranev1.AddToScheme(scheme))\\n}\\n\\n// Reconciler structure to handle reconciliation logic\\ntype Reconciler struct {\\n  client.Client            // Controller-runtime client\\n  scheme     *runtime.Scheme // Scheme for managing API types\\n  kubeClient *kubernetes.Clientset // Kubernetes clientset for direct API calls\\n}\\n\\n// Reconcile function handles the main logic for the controller\\nfunc (r *Reconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\\n  log := log.FromContext(ctx).WithValues(\\"application\\", req.NamespacedName) // Create contextual logger\\n  log.Info(\\"reconciling application\\")\\n\\n  // Fetch the Application resource by name and namespace\\n  var application cranev1.Application\\n  err := r.Client.Get(ctx, req.NamespacedName, &application)\\n  if err != nil {\\n    // If resource is not found, attempt to clean up associated resources\\n    if k8serrors.IsNotFound(err) {\\n      err = craneKubeUtils.DeleteApplication(ctx, req, r.kubeClient)\\n      if err != nil {\\n        return ctrl.Result{}, fmt.Errorf(\\"couldn\'t delete resources: %s\\", err)\\n      }\\n      return ctrl.Result{}, nil\\n    }\\n  }\\n\\n  // Create or update the Kubernetes deployment for the Application resource\\n  err = craneKubeUtils.ApplyApplication(ctx, req, application, r.kubeClient)\\n  if err != nil {\\n    return ctrl.Result{}, fmt.Errorf(\\"couldn\'t create or update deployment: %s\\", err)\\n  }\\n\\n  return ctrl.Result{}, nil // Reconcile completed successfully\\n}\\n\\n// RunController initializes and starts the Kubernetes controller\\nfunc RunController() {\\n  var (\\n    config *rest.Config\\n    err    error\\n  )\\n\\n  // Determine the kubeconfig file path (used for local development)\\n  kubeconfigFilePath := filepath.Join(homedir.HomeDir(), \\".kube\\", \\"config\\")\\n  if _, err := os.Stat(kubeconfigFilePath); errors.Is(err, os.ErrNotExist) {\\n    // If kubeconfig does not exist, try to use in-cluster configuration\\n    config, err = rest.InClusterConfig()\\n    if err != nil {\\n      panic(err.Error()) // Exit if no valid configuration is found\\n    }\\n  } else {\\n    // Load configuration from kubeconfig file\\n    config, err = clientcmd.BuildConfigFromFlags(\\"\\", kubeconfigFilePath)\\n    if err != nil {\\n      panic(err.Error())\\n    }\\n  }\\n\\n  // Create a Kubernetes clientset\\n  clientset, err := kubernetes.NewForConfig(config)\\n  if err != nil {\\n    panic(err.Error())\\n  }\\n\\n  // Set up the logger for the controller\\n  ctrl.SetLogger(zap.New())\\n\\n  // Create a new manager for the controller\\n  mgr, err := ctrl.NewManager(config, ctrl.Options{\\n    Scheme: scheme,\\n  })\\n  if err != nil {\\n    setupLog.Error(err, \\"unable to start manager\\")\\n    os.Exit(1)\\n  }\\n\\n  // Create and register the reconciler with the manager\\n  err = ctrl.NewControllerManagedBy(mgr).\\n    For(&cranev1.Application{}). // Specify the resource type the controller manages\\n    Complete(&Reconciler{\\n      Client:     mgr.GetClient(),   // Use manager\'s client\\n      scheme:     mgr.GetScheme(),  // Use manager\'s scheme\\n      kubeClient: clientset,        // Use clientset for direct API calls\\n    })\\n\\n  if err != nil {\\n    setupLog.Error(err, \\"unable to create controller\\")\\n    os.Exit(1)\\n  }\\n\\n  // Start the manager and handle graceful shutdown\\n  setupLog.Info(\\"starting manager\\")\\n  if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil {\\n    setupLog.Error(err, \\"error running manager\\")\\n    os.Exit(1)\\n  }\\n}\\n```\\n\\n#### Lets explain the Controller Code\\n\\nLets take a deep dive into the code above so we can have a good understanding of whats going on in that file.\\n\\nAt the top of the file we are importing the required libraries that we shall use. Read the comments in this code snippet to understand what each import does.\\n\\n```go\\nimport (\\n  \\"context\\" // Provides functionality for managing and passing context, especially useful in request-scoped operations.\\n  \\"errors\\"  // Standard Go package for creating and handling errors.\\n  \\"fmt\\"     // Provides formatted I/O with functions similar to C\'s printf and scanf.\\n  \\"os\\"      // Handles OS-level functionalities such as reading environment variables and file system operations.\\n  \\"path/filepath\\" // Helps in manipulating and building file paths in a cross-platform way.\\n\\n  cranev1 \\"github.com/jim-junior/crane-operator/api/v1\\" // Imports the custom CRD definitions (e.g., Application) for this operator.\\n  craneKubeUtils \\"github.com/jim-junior/crane-operator/kube\\" // Imports helper utilities for interacting with Kubernetes resources.\\n\\n  k8serrors \\"k8s.io/apimachinery/pkg/api/errors\\" // Provides utilities for working with Kubernetes API errors.\\n  \\"k8s.io/apimachinery/pkg/runtime\\" // Handles runtime types and schemes for Kubernetes objects.\\n  utilruntime \\"k8s.io/apimachinery/pkg/util/runtime\\" // Contains utility functions for runtime error handling and recovery.\\n  \\"k8s.io/client-go/kubernetes\\" // Kubernetes client-go library for interacting with the Kubernetes API server.\\n  \\"k8s.io/client-go/rest\\" // Provides tools for working with REST configurations, especially for in-cluster access.\\n  \\"k8s.io/client-go/tools/clientcmd\\" // Handles loading and parsing kubeconfig files for out-of-cluster Kubernetes access.\\n  \\"k8s.io/client-go/util/homedir\\" // Utility package to get the user\'s home directory path.\\n\\n  ctrl \\"sigs.k8s.io/controller-runtime\\" // Main package for building controllers using the Kubernetes Controller Runtime.\\n  \\"sigs.k8s.io/controller-runtime/pkg/client\\" // Provides a dynamic client for interacting with Kubernetes objects.\\n  \\"sigs.k8s.io/controller-runtime/pkg/log\\" // Utilities for logging within the Controller Runtime framework.\\n  \\"sigs.k8s.io/controller-runtime/pkg/log/zap\\" // Provides a Zap-based logger for the Controller Runtime.\\n)\\n```\\n\\nWe have an `init` function that initialize the Kubernetes scheme by registering the API group we defined for our CRD.\\n\\nNext lets look ar the `RunController` function at the bottom of the file. First we need to get access to a Kuberentes client or clientset that will allow use to interact with the Kubernetes API Server when carrying out CRUD operations on our cluster. That what these first 27 lines are trying to accomplish. We shall call the `RunController` function in the `main.go` file of our program as it will be the entry point of out Kubernetes Operator\\n\\n```go\\nkubeconfigFilePath := filepath.Join(homedir.HomeDir(), \\".kube\\", \\"config\\")\\n  if _, err := os.Stat(kubeconfigFilePath); errors.Is(err, os.ErrNotExist) {\\n    // If kubeconfig does not exist, try to use in-cluster configuration\\n    config, err = rest.InClusterConfig()\\n    if err != nil {\\n      panic(err.Error()) // Exit if no valid configuration is found\\n    }\\n  } else {\\n    // Load configuration from kubeconfig file\\n    config, err = clientcmd.BuildConfigFromFlags(\\"\\", kubeconfigFilePath)\\n    if err != nil {\\n      panic(err.Error())\\n    }\\n  }\\n\\n  // Create a Kubernetes clientset\\n  clientset, err := kubernetes.NewForConfig(config)\\n  if err != nil {\\n    panic(err.Error())\\n  }\\n```\\n\\nWe then setup logging wth zap. This will help us in debugging\\n\\n```go\\nctrl.SetLogger(zap.New())\\n```\\n\\nWe then setup our Manager. \\n\\n```go\\n// Create a new manager for the controller\\n  mgr, err := ctrl.NewManager(config, ctrl.Options{\\n    Scheme: scheme,\\n  })\\n  if err != nil {\\n    setupLog.Error(err, \\"unable to start manager\\")\\n    os.Exit(1)\\n  }\\n\\n  // Create and register the reconciler with the manager\\n  err = ctrl.NewControllerManagedBy(mgr).\\n    For(&cranev1.Application{}). // Specify the resource type the controller manages\\n    Complete(&Reconciler{\\n      Client:     mgr.GetClient(),   // Use manager\'s client\\n      scheme:     mgr.GetScheme(),  // Use manager\'s scheme\\n      kubeClient: clientset,        // Use clientset for direct API calls\\n    })\\n\\n  if err != nil {\\n    setupLog.Error(err, \\"unable to create controller\\")\\n    os.Exit(1)\\n  }\\n\\n  // Start the manager and handle graceful shutdown\\n  setupLog.Info(\\"starting manager\\")\\n  if err := mgr.Start(ctrl.SetupSignalHandler()); err != nil {\\n    setupLog.Error(err, \\"error running manager\\")\\n    os.Exit(1)\\n  }\\n```\\n\\nThis code initializes and starts the core components of the Kubernetes controller. First, a manager (`mgr`) is created using the `ctrl.NewManager` function, which serves as the runtime environment for the controller, handling shared resources, clients, and the scheme that defines the resource types the manager can work with. If the manager cannot start due to configuration issues, an error is logged, and the program exits. Next, a reconciler is created and registered with the manager. The reconciler defines the logic for ensuring the desired state of the custom resource (`Application`) matches the actual state in the cluster. This is done using `ctrl.NewControllerManagedBy`, which specifies the resource type the controller will manage and configures the reconciler with the manager\'s client, scheme, and a Kubernetes clientset for making direct API calls. If the controller cannot be created or registered, the program exits with an error. Finally, the manager is started using `mgr.Start`, which begins watching the specified resource and handling reconciliation requests. A signal handler is set up to ensure graceful shutdowns. If the manager fails to start, an error is logged, and the program exits. This setup combines the manager and reconciler to enable the operator to monitor and maintain the desired state of custom resources in the Kubernetes cluster.\\n\\nNext lets define our Reconciler and `Reconcile` function.\\n\\nWe define the Reconciler struct. This is the struct that we used in the `ctrl.NewControllerManagedBy` when we initialized the controller. The struct should have a method called `Reconcile` that handles the main logic for the controller, i.e it reconciles the desired state into actual Kubernetes Objects.\\n\\n```go\\ntype Reconciler struct {\\n  client.Client\\n  scheme     *runtime.Scheme\\n  kubeClient *kubernetes.Clientset\\n}\\n\\nfunc (r *Reconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\\n  log := log.FromContext(ctx).WithValues(\\"application\\", req.NamespacedName) // Create contextual logger\\n  log.Info(\\"reconciling application\\")\\n\\n  // Fetch the Application resource by name and namespace\\n  var application cranev1.Application\\n  err := r.Client.Get(ctx, req.NamespacedName, &application)\\n  if err != nil {\\n    // If resource is not found, attempt to clean up associated resources\\n    if k8serrors.IsNotFound(err) {\\n      err = craneKubeUtils.DeleteApplication(ctx, req, r.kubeClient)\\n      if err != nil {\\n        return ctrl.Result{}, fmt.Errorf(\\"couldn\'t delete resources: %s\\", err)\\n      }\\n      return ctrl.Result{}, nil\\n    }\\n  }\\n\\n  // Create or update the Kubernetes deployment for the Application resource\\n  err = craneKubeUtils.ApplyApplication(ctx, req, application, r.kubeClient)\\n  if err != nil {\\n    return ctrl.Result{}, fmt.Errorf(\\"couldn\'t create or update deployment: %s\\", err)\\n  }\\n\\n  return ctrl.Result{}, nil // Reconcile completed successfully\\n}\\n```\\n\\n> __Note__: I will not include utility functions imported as `craneKubeUtils` because they are not really necessary for this article but they are basically functions that create *Deployements* and *Services* from the CRD Spec. However, in the code hosted on the GitHub repository, you can find them in this file. [https://github.com/jim-junior/crane-operator/blob/main/kube/application.go](https://github.com/jim-junior/crane-operator/blob/main/kube/application.go)\\n\\nNext in your `main.go` file import the `RunController` function from the `controller` package and call it in you `main()` function.\\n\\n```go\\npackage main\\n\\nimport \\"github.com/jim-junior/crane-operator/cmd/controller\\"\\n\\nfunc main() {\\n  controller.RunController()\\n}\\n```\\n\\n### Testing the Controller\\n\\nNow that we are done writing the code for our controller, we can test it. First you will have to have you kubernetes cluster running and you config setup. Make sure the host machine that you are running it on is already connected to the kubernetes cluster. you can verify this by running any `kubectl` command such as:\\n\\n```bash\\nkubectl get nodes\\n# If it setup it might return something like this\\n# NAME       STATUS   ROLES           AGE    VERSION\\n# minikube   Ready    control-plane   228d   v1.27.4\\n\\n# If its not setup it might return an error like: \\n# E1222 11:35:37.597805   25720 memcache.go:265] couldn\'t get current server API group list: Get \\"http://localhost:8080/api?timeout=32s\\": dial tcp [::1]:8080: connectex: No connection could be made because the target machine actively refused it.\\n```\\n\\nIf all is well you can move on to test our controller by running:\\n\\n```bash\\ngo run main.go \\n```\\n\\nThe expected log output is something like this\\n\\n```log\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"logger\\":\\"setup\\",\\"msg\\":\\"starting manager\\"}\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"logger\\":\\"controller-runtime.metrics\\",\\"msg\\":\\"Starting metrics server\\"}\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"msg\\":\\"Starting EventSource\\",\\"controller\\":\\"application\\",\\"controllerGroup\\":\\"cloud.cranom.tech\\",\\"controllerKind\\":\\"Application\\",\\"source\\":\\"kind source: *v1.Application\\"}\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"msg\\":\\"Starting Controller\\",\\"controller\\":\\"application\\",\\"controllerGroup\\":\\"cloud.cranom.tech\\",\\"controllerKind\\":\\"Application\\"}\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"logger\\":\\"controller-runtime.metrics\\",\\"msg\\":\\"Serving metrics server\\",\\"bindAddress\\":\\":8080\\",\\"secure\\":false}\\n{\\"level\\":\\"info\\",\\"ts\\":\\"2024-12-22T11:08:23+03:00\\",\\"msg\\":\\"Starting workers\\",\\"controller\\":\\"application\\",\\"controllerGroup\\":\\"cloud.cranom.tech\\",\\"controllerKind\\":\\"Application\\",\\"worker count\\":1}\\n```\\n\\nIf your getting an error or having a hard time running the controller for some reason, you can open an issue on the Github Repository where the source code is hosted or you can leave it in the comment section if your reading this article on Dev.to or Medium.\\n\\nIf all is good. We can now try applying an example CRD and test if our operator is carrying out its expected functionality.\\n\\nIn the `yaml/examples` directory of the github repository i have placed there a cofigurations or our custom `Application` resource. These configuration are for deploying a Wordpress instance with a Mysql database. there are three files. `mysql.yaml`, `wp-secrets.yml` and `wordpress.yml`.\\n\\nYou can apply them by running tthe `kubectl apply` commands in this order.\\n\\n```bash\\n# Secrets for the Environment Variables\\nkubectl apply yaml/examples/wp-secrets.yml\\n# Mysql instance\\nkubectl apply yaml/examples/mysql.yml\\n# Wordpress instance\\nkubectl apply yaml/examples/wordpress.yml\\n```\\n\\nYou can also copy the code from these files on Github\\n\\n- [https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/mysql.yaml](https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/mysql.yaml)\\n- [https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/wordpress.yml](https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/wordpress.yml)\\n- [https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/wp-secrets.yml](https://github.com/jim-junior/crane-operator/blob/main/yaml/examples/wp-secrets.yml)\\n\\nThe configurations in those files are for a Wordpress application that will listen on the node port of `30080`.\\n\\n### Deploying the Operator\\n\\nSince we now know the kubernetes operator works, Lets move on to deploying it. To deploy it, we shall have to carry out the following steps.\\n\\n- Generate a docker image for the operator\\n- Publish it to the Docker registry\\n- We can they deploy it on our cluster.\\n\\nWe shall move on to generating a container image for the Kubernetes Operator. We shall use the [golang](https://go.dev/) image as our base image for the container since this is a golang project. Copy this code and add it to your `DockerFile` in the root of you project.\\n\\n```dockerfile\\n# Building the binary of the App\\nFROM golang:1.22.5 AS build\\n\\n# `boilerplate` should be replaced with your project name\\nWORKDIR /go/src/boilerplate\\n\\n# Copy all the Code and stuff to compile everything\\nCOPY . .\\n\\n# Downloads all the dependencies in advance (could be left out, but it\'s more clear this way)\\nRUN go mod download\\n\\n# Builds the application as a staticly linked one, to allow it to run on alpine\\nRUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -installsuffix cgo -o app .\\n\\n\\n# Moving the binary to the \'final Image\' to make it smaller\\nFROM alpine:latest as release\\n\\nWORKDIR /app\\n\\n\\n# `boilerplate` should be replaced here as well\\nCOPY --from=build /go/src/boilerplate/app .\\n\\n# Add packages\\nRUN apk -U upgrade \\\\\\n  && apk add --no-cache dumb-init ca-certificates \\\\\\n  && chmod +x /app/app\\n\\n\\nENTRYPOINT [ \\"/app/app\\" ]\\n```\\n\\nYou can then build the container using docker and then publish it to a container registry of your choice.\\n\\nThen next is to deploy our cluster. We shall create a Kubernetes deployment for our Operator. Below i have a simple Kubernetes *Deployment* object for the operator.\\n\\n```yaml\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  name: crane-operator\\nspec:\\n  replicas: 1\\n  selector:\\n    matchLabels:\\n      app: crane-operator\\n  template:\\n    metadata:\\n      labels:\\n        app: crane-operator\\n    spec:\\n      containers:\\n      - name: controller\\n        image: jimjuniorb/crane-operator:latest\\n```\\n\\n__Congrats!!!__ you now have a running Kubernetes operator on your cluster. You can now adjust it in what ever way you would like.\\n\\nI would recommend looking into frameworks like Operator SDK or Kube builder if you want to build more complex Operators. I have also included a Github Action workflow file for deploying the Operator using GitHub actions each time a new Release tag is created.\\n\\nWell thats it for Today. Thanks for following through till the End of this article. Below are a few references i used that you might find helpful.\\n\\n\\n## References\\n\\nBrandon Philips, (November 3, 2016). Introducing Operators: Putting Operational Knowledge into Software. Internet Archive Wayback Machine. [https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html](https://web.archive.org/web/20170129131616/https://coreos.com/blog/introducing-operators.html)\\n\\nCNCF TAG App-Delivery Operator Working Group, CNCF Operator White Paper - Final Version. Github. [https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md](https://github.com/cncf/tag-app-delivery/blob/163962c4b1cd70d085107fc579e3e04c2e14d59c/operator-wg/whitepaper/Operator-WhitePaper_v1-0.md)\\n\\nKubernetes Documentation, Custom Resources. [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/)\\n\\nKubernetes Documentation, Controllers. [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/](https://kubernetes.io/docs/concepts/architecture/controller/)\\n\\nYoutube, Kubernetes API Versioning: A Deep dive. [https://www.youtube.com/live/-jtGM6WnF1Q?si=-6tfrlwyTf-NSizL](https://www.youtube.com/live/-jtGM6WnF1Q?si=-6tfrlwyTf-NSizL)"},{"id":"how-to-create-a-responsive-custom-video-player-in-react","metadata":{"permalink":"/open-ug/blog/how-to-create-a-responsive-custom-video-player-in-react","source":"@site/blog/2024-05-04-player.md","title":"How to create a responsive custom video player in React","description":"How to create a responsive custom video player in React","date":"2024-05-04T00:00:00.000Z","tags":[{"label":"video-player","permalink":"/open-ug/blog/tags/video-player"},{"label":"reactjs-media","permalink":"/open-ug/blog/tags/reactjs-media"},{"label":"react","permalink":"/open-ug/blog/tags/react"}],"readingTime":3.21,"hasTruncateMarker":true,"authors":[{"name":"Beingana Jim Junior","title":"Open UG Team","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"}],"frontMatter":{"slug":"how-to-create-a-responsive-custom-video-player-in-react","title":"How to create a responsive custom video player in React","authors":{"name":"Beingana Jim Junior","title":"Open UG Team","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"},"tags":["video-player","reactjs-media","react"]},"unlisted":false,"prevItem":{"title":"Building a Kubernetes Operator | A Practical Guide","permalink":"/open-ug/blog/building-a-kubernetes-operator"},"nextItem":{"title":"How to create Mobile Money Payments in Python in Uganda","permalink":"/open-ug/blog/making-mobile-money-payments-in-python"}},"content":"![How to create a responsive custom video player in React](./rmjsbanner.png)\\n\\n\\nVideo players are essential for applications that showcase video content. While the default HTML5 player offers basic functionalities like play, pause, and volume control, its appearance can vary significantly across browsers and devices.  This inconsistency can be a drawback for a polished user experience.\\n\\nIn this article, we\'ll guide you through creating a responsive custom video player using a library I built called `reactjs-media`. This approach lets you avoid the limitations of the default HTML5 player and the complexity of building a video player from scratch. The reactjs-media library provides more react approach to building your custom player with a wide range of features and customization options.\\n\\n\x3c!--truncate--\x3e\\n\\n## Getting started\\n\\nBefore we dive into building our custom video player, I assume your already have a React project set up. If not, you can create a new React project using Create React App or Vite or any of your preferred React setup.\\n\\nWe shall then go ahead and install the reactjs-media library using npm or yarn.\\n\\n```bash\\nnpm install reactjs-media\\n```\\n\\nor\\n\\n```bash\\nyarn add reactjs-media\\n```\\n\\n## Creating a custom video player\\n\\nTo create a Video player we shall start with the default player provided by the library(Which is Awesome too).\\n\\nAll you have to do is import the `Video` component from `reactjs-media` \\n\\n```jsx\\nimport { Video } from \\"reactjs-media\\";\\n\\nconst App = () => {\\n  return (\\n    <div>\\n      <Video\\n        src={\\"/video.mkv\\"}\\n        controls={true}\\n        height={500}\\n        width={800}\\n        poster={\\n          \\"https://hips.hearstapps.com/hmg-prod/images/ripley-pa-108-011822-01629-r-661067043d66f.jpg?resize=980:*\\"\\n        }\\n      />\\n    </div>\\n  );\\n};\\n```\\n\\n**And Voila!** You have a video player in your application.\\n\\nimport {Video} from \'reactjs-media\';\\n\\n<Video \\ncontrols\\nsrc=\\"https://videos.pexels.com/video-files/4524598/4524598-sd_640_360_25fps.mp4\\"\\nposter=\\"https://images.pexels.com/photos/848573/pexels-photo-848573.jpeg?auto=compress&cs=tinysrgb&w=800\\"\\nheight={400}\\n/>\\n\\n## What are the props?\\n\\nThe Video Component accepts a number props that are defined under the `VideoProps` interface(If you use TypeScript in your Projects). These can be both attributes of the player or event handlers.\\n\\nWe shall start with the basics:\\n\\n- `src`: The source of the video file.\\n- `controls`: A boolean value to show or hide the video controls. It defaults to `false`\\n- `height`: The height of the video player.(This is added as `maxHeight` in the styles)\\n- `width`: The width of the video player.(This is added as `maxWidth` in the styles)\\n- `poster`: The poster image to be displayed before the video starts playing.\\n- `contextMenu`: A boolean value to show or hide the context menu. It defaults to `false`\\n\\n\\n## Handling Events\\n\\nThe Video Component also provides a number of event handlers that you can use to listen to events on the video player.\\n\\n- `onPlay`: This event is fired when the video starts playing.\\n- `onPause`: This event is fired when the video is paused.\\n- `onEnded`: This event is fired when the video has ended.\\n- `onTimeUpdate`: This event is fired when the video is playing and the time is updated.\\n- `onVolumeChange`: This event is fired when the volume of the video is changed.\\n- `onSeeking`: This event is fired when the video is seeking.\\n- `onSeeked`: This event is fired when the video has finished seeking.\\n- `onCanPlay`: This event is fired when the video can be played.\\n\\nExample:\\n\\n```jsx\\n<Video\\n  src={\\"/video.mkv\\"}\\n  controls={true}\\n  height={500}\\n  width={800}\\n  poster={\\n    \\"https://hips.hearstapps.com/hmg-prod/images/ripley-pa-108-011822-01629-r-661067043d66f.jpg?resize=980:*\\"\\n  }\\n  onPlay={() => console.log(\\"Video is playing\\")}\\n  onPause={() => console.log(\\"Video is paused\\")}\\n  onEnded={() => console.log(\\"Video has ended\\")}\\n  onTimeUpdate={(time) => console.log(\\"Time is updated\\", time)}\\n/>\\n\\n```\\n\\n> **Note:** If you want to build a player with your own Completely Custom UI. You can check out the [Building a custom player](https://open.cranom.cloud/reactjs-media/building-custom-player) guide in the `reactjs-media` documentation.\\n\\n\\n## Conclusion\\n\\nIn this article, we have learned how to create a responsive custom video player in React using the `reactjs-media` library. This library provides a set of components and a simple API to create a customizable media player for your application. You can explore more features and customization options by checking out the [`reactjs-media` documentation](https://open.cranom.cloud/reactjs-media/intro).\\n\\n\\n[![DigitalOcean Referral Badge](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg)](https://www.digitalocean.com/?refcode=ad96e8b378d5&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge)"},{"id":"making-mobile-money-payments-in-python","metadata":{"permalink":"/open-ug/blog/making-mobile-money-payments-in-python","source":"@site/blog/2024-05-03-mobile-money/index.md","title":"How to create Mobile Money Payments in Python in Uganda","description":"How to create Mobile Money Payments in Python in Uganda","date":"2024-05-03T00:00:00.000Z","tags":[{"label":"python","permalink":"/open-ug/blog/tags/python"},{"label":"ugmobilemoney","permalink":"/open-ug/blog/tags/ugmobilemoney"},{"label":"mtn-momo","permalink":"/open-ug/blog/tags/mtn-momo"}],"readingTime":4.065,"hasTruncateMarker":true,"authors":[{"name":"Beingana Jim Junior","title":"Open UG Team","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"}],"frontMatter":{"slug":"making-mobile-money-payments-in-python","title":"How to create Mobile Money Payments in Python in Uganda","authors":{"name":"Beingana Jim Junior","title":"Open UG Team","url":"https://github.com/jim-junior","image_url":"https://avatars.githubusercontent.com/u/69729988?v=4","imageURL":"https://avatars.githubusercontent.com/u/69729988?v=4"},"tags":["python","ugmobilemoney","mtn-momo"]},"unlisted":false,"prevItem":{"title":"How to create a responsive custom video player in React","permalink":"/open-ug/blog/how-to-create-a-responsive-custom-video-player-in-react"}},"content":"![How to create Mobile Money Payments in Python in Uganda](./banner.png)\\n\\nIn this article, we will learn how to create Mobile Money Payments in Python in Uganda using different Mobile Money APIs, while utilizing the `ugmobilemoney` library.\\n\\n\x3c!--truncate--\x3e\\n\\n## Introduction\\n\\nMobile Money is a digital payment system that allows users to conduct financial transactions using their mobile phones. It is a popular payment method in Uganda, with the most popular Mobile Money service providers being MTN Mobile Money, Airtel Money, and Africell Money.\\n\\nIn this article, we will focus on creating Mobile Money Payments in Python in Uganda using the `ugmobilemoney` library. This library provides a simple and easy-to-use interface for interacting with different Mobile Money APIs in Uganda.\\n\\nThe `ugmobilemoney` library currently supports a number of Mobile Money APIs in Uganda, including:\\n\\n- MTN Mobile Money API\\n- Airtel Money API\\n- Flutterwave API\\n- Yo Uganda API\\n- Xente API\\n\\nIn this article, we will focus on creating Mobile Money Payments using the MTN Mobile Money API, If you want other APIs, you can check the [`ugmobilemoney` documentation](https://open.cranom.cloud/ugmobilemoney/intro).\\n\\n## Prerequisites\\n\\nBefore we get started, you will need to have the following prerequisites:\\n\\n- Python installed on your machine\\n- An active MTN Mobile Money API key and Subscription Key\\n\\n> If you don\'t have an MTN Mobile Money API key or Subscription Key, you can follow this **Step by Step Guide** to get one: [How to getting Started with MTN MOMO API](https://open.cranom.cloud/ugmobilemoney/mtn-momo/getting-started)\\n\\n## Installing the `ugmobilemoney` library\\n\\nTo get started, you will need to install the `ugmobilemoney` library using `pip`. You can do this by running the following command:\\n\\n```bash\\npip install ugmobilemoney\\n```\\n\\nOnce you have installed the `ugmobilemoney` library, it should be accessible in your Python environment and `mobile_money` module.\\n\\n## Creating Mobile Money Payments\\n\\nAt this point, you should have the `ugmobilemoney` library installed and your MTN Mobile Money API key and Subscription Key ready. Now, let\'s create a simple Mobile Money Payment using the `ugmobilemoney` library.\\n\\nThe MTN MOMO API provides differect services in form of Products. When you want to recieve money from users you use the [**Collections**](https://momodeveloper.mtn.com/product#product=collections) Product.\\n\\nThe `ugmobilemoney` library provides a simple interface to interact with each of the Products. For example if you want to use the Collections Product, you can import the `Collection` class from the `mobile_money.momo` module and use it to create a Mobile Money Payment.\\n\\nHere is an example of how you can create a Mobile Money Payment using the `Collection` class:\\n\\n```python\\nfrom mobile_money.momo import Collection\\nfrom mobile_money import generate_uuid\\n\\ncollection = Collection(\\n    subscription_key=SUBSCRIPTION_KEY,\\n    api_user=API_USER,\\n    api_key=API_KEY,\\n    callback_url=\\"http://mydomain.com/webhooks/mtn/\\",\\n    production=False,\\n)\\n\\ntransaction_reference = generate_uuid()\\n# Request to pay\\nresponse = COLLECTION.collect(\\n    amount=\\"100\\",\\n    phone_number=\\"256772123456\\",\\n    currency=\\"UGX\\",\\n    external_id=\\"external id\\",\\n    reference_id=transaction_reference,\\n    payee_note=\\"test\\",\\n    payer_message=\\"test\\",\\n)\\n\\nprint(response)\\n\\n# >>> <Response [202 Accepted]>\\n```\\n\\nIn this example, we first import the `Collection` class from the `ugmobilemoney.momo` module. We then create an instance of the `Collection` class, passing in the required parameters such as the Subscription Key, API User, API Key, and callback URL.\\n\\nWe then generate a unique transaction reference using the `generate_uuid` function. We then call the `collect` method on the `Collection` instance, passing in the required parameters such as the amount, phone number, currency, external ID, reference ID, payee note, and payer message.\\n\\nThe `collect` method will send a request to the MTN MOMO API to create a Mobile Money Payment. If the request is successful, the method will return a response object with a status code of `202 Accepted`.\\n\\n## Disbursing (Sending) Mobile Money Payments\\n\\nThe MTN MOMO API also provides a service for sending Mobile Money Payments in bulk to different recipients. This service is called Disbursements. You can use the `Disbursement` class from the `mobile_money.momo` module to send Mobile Money Payments using the Disbursements service.\\n\\nHere is an example of how you can send Mobile Money Payments using the `Disbursement` class:\\n\\n```python\\nfrom mobile_money.momo import Disbursement\\n\\ndisbursement = Disbursement(\\n    subscription_key=SUBSCRIPTION_KEY,\\n    api_user=API_USER,\\n    api_key=API_KEY,\\n    callback_url=\\"http://mydomain.com/webhooks/mtn/\\",\\n    production=False,\\n)\\n\\ntransaction_reference = generate_uuid()\\n\\nresponse = disbursement.send(\\n    amount=\\"100\\",\\n    phone_number=\\"256772123456\\",\\n    currency=\\"UGX\\",\\n    external_id=\\"external id\\",\\n    reference_id=transaction_reference,\\n    payee_note=\\"test\\",\\n    payer_message=\\"test\\",\\n)\\n\\nprint(response)\\n\\n# >>> <Response [202 Accepted]>\\n```\\n\\n## Conclusion\\n\\nIn this article, we have learned how to create Mobile Money Payments in Python in Uganda using the `ugmobilemoney` library. We have seen how to create Mobile Money Payments using the MTN Mobile Money API, and how to send Mobile Money Payments using the Disbursements service.\\n\\nThe `ugmobilemoney` library also supports other Payment Providers in Uganda, such as Airtel Money, Flutterwave, Yo Uganda, and Xente, It also tries to fully implement their APIs making it not only limited to mobile money payments but also other services like Airtime Topup, Bill Payments, Card Payments as long as the Service Provider has an API for it that is well documented.\\n\\nYou can learn more about the `ugmobilemoney` library and how to use it by checking out the [documentation](https://open.cranom.cloud/ugmobilemoney/intro). or its Code on [Github](https://github.com/open-ug/ugmobilemoney-py)\\n\\n\\n[![DigitalOcean Referral Badge](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg)](https://www.digitalocean.com/?refcode=ad96e8b378d5&utm_campaign=Referral_Invite&utm_medium=Referral_Program&utm_source=badge)"}]}')}}]);